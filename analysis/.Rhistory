if (!file.exists(paste0(gtfdest, "/", urlSpecific, ".gtf"))) {
chromNum.1n <- speciesChromnumCsv$chromNum.1n[speciesChromnumCsv$species == species]
if (!is.na(chromNum.1n)) {
resultsCsv <- paste0("C:/Users/zhaob/Desktop/gene_density/results/vertebrates/genomicData/", gsub(" ", "_", species), ".csv")
csv <- fread(resultsCsv)
if (nrow(csv) > 0) {
urlBase <- "https://ftp.ensembl.org/pub/release-112/gtf/"
urlSpecific <- tolower(paste0(gsub(" ", "_", species)))
url <- paste0(urlBase, urlSpecific, "/")
checksum <- readLines(paste0(url, "CHECKSUMS"))
url2 <- checksum[grepl("(?<!\\.abinitio)(?<!\\.chr)\\.gtf\\.gz$", checksum, perl = TRUE)]
url2.5 <- sub(".*\\s", "", url2)
url3 <- paste0(url, url2.5)
h <- new_handle()
handle_setopt(h, timeout = 360)
curl_download(url3, paste0(gtfdest, "/", urlSpecific, ".gtf.gz"), handle = h)
gunzip(paste0(gtfdest, "/", urlSpecific, ".gtf.gz"), paste0(gtfdest, "/", urlSpecific, ".gtf"), remove = TRUE)
gtfFilePath <- paste0(gtfdest, "/", urlSpecific, ".gtf")
asmblyGeneCount <- dataFromGtf(gtfFilePath)
csv$asmblyGeneCount <- asmblyGeneCount
fwrite(csv, file = resultsCsv, row.names = FALSE)
}
}
}
execTime <- round(as.numeric(difftime(Sys.time(), startTime, units = "mins")), 2)
print(noquote(paste0("   ", execTime, " minutes")))
}
speciesChromnumCsvPath <- "C:/Users/zhaob/Desktop/gene_density/data/vertebrates/speciesChromnum.csv"
library(data.table)
library(R.utils)
library(bit64)
library(curl)
speciesChromnumCsv <- fread(speciesChromnumCsvPath)
dataFromGtf <- function(gtfFilePath) {
# read gtf
gtf <- fread(gtfFilePath, header = FALSE, showProgress = TRUE)
# filter for genes only
gtf <- gtf[which(gtf[, 3] == "gene"), ]
asmblyGeneCount <- nrow(gtf[!(gtf[[1]] %in% c("mt", "mito", "mitochondrial", "nonchromosomal")), ])
return(asmblyGeneCount)
}
gtfdest <- "C:/Users/zhaob/Desktop/patchgtf"
for (species in speciesChromnumCsv$species[1:121]) {
startTime <- Sys.time()
gc()
print(noquote(species))
urlSpecific <- tolower(paste0(gsub(" ", "_", species)))
if (!file.exists(paste0(gtfdest, "/", urlSpecific, ".gtf"))) {
chromNum.1n <- speciesChromnumCsv$chromNum.1n[speciesChromnumCsv$species == species]
if (!is.na(chromNum.1n)) {
resultsCsv <- paste0("C:/Users/zhaob/Desktop/gene_density/results/vertebrates/genomicData/", gsub(" ", "_", species), ".csv")
csv <- fread(resultsCsv)
if (nrow(csv) > 0) {
urlBase <- "https://ftp.ensembl.org/pub/release-112/gtf/"
urlSpecific <- tolower(paste0(gsub(" ", "_", species)))
url <- paste0(urlBase, urlSpecific, "/")
checksum <- readLines(paste0(url, "CHECKSUMS"))
url2 <- checksum[grepl("(?<!\\.abinitio)(?<!\\.chr)\\.gtf\\.gz$", checksum, perl = TRUE)]
url2.5 <- sub(".*\\s", "", url2)
url3 <- paste0(url, url2.5)
h <- new_handle()
handle_setopt(h, timeout = 360)
curl_download(url3, paste0(gtfdest, "/", urlSpecific, ".gtf.gz"), handle = h)
gunzip(paste0(gtfdest, "/", urlSpecific, ".gtf.gz"), paste0(gtfdest, "/", urlSpecific, ".gtf"), remove = TRUE)
gtfFilePath <- paste0(gtfdest, "/", urlSpecific, ".gtf")
asmblyGeneCount <- dataFromGtf(gtfFilePath)
csv$asmblyGeneCount <- asmblyGeneCount
fwrite(csv, file = resultsCsv, row.names = FALSE)
}
}
}
execTime <- round(as.numeric(difftime(Sys.time(), startTime, units = "mins")), 2)
print(noquote(paste0("   ", execTime, " minutes")))
}
speciesChromnumCsvPath <- "C:/Users/zhaob/Desktop/gene_density/data/vertebrates/speciesChromnum.csv"
library(data.table)
library(R.utils)
library(bit64)
library(curl)
speciesChromnumCsv <- fread(speciesChromnumCsvPath)
dataFromGtf <- function(gtfFilePath) {
# read gtf
gtf <- fread(gtfFilePath, header = FALSE, showProgress = TRUE)
# filter for genes only
gtf <- gtf[which(gtf[, 3] == "gene"), ]
asmblyGeneCount <- nrow(gtf[!(gtf[[1]] %in% c("mt", "mito", "mitochondrial", "nonchromosomal")), ])
return(asmblyGeneCount)
}
gtfdest <- "C:/Users/zhaob/Desktop/patchgtf"
for (species in speciesChromnumCsv$species[1:121]) {
startTime <- Sys.time()
gc()
print(noquote(species))
urlSpecific <- tolower(paste0(gsub(" ", "_", species)))
if (!file.exists(paste0(gtfdest, "/", urlSpecific, ".gtf"))) {
chromNum.1n <- speciesChromnumCsv$chromNum.1n[speciesChromnumCsv$species == species]
if (!is.na(chromNum.1n)) {
resultsCsv <- paste0("C:/Users/zhaob/Desktop/gene_density/results/vertebrates/individualSpeciesResults/", gsub(" ", "_", species), ".csv")
csv <- fread(resultsCsv)
if (nrow(csv) > 0) {
urlBase <- "https://ftp.ensembl.org/pub/release-112/gtf/"
urlSpecific <- tolower(paste0(gsub(" ", "_", species)))
url <- paste0(urlBase, urlSpecific, "/")
checksum <- readLines(paste0(url, "CHECKSUMS"))
url2 <- checksum[grepl("(?<!\\.abinitio)(?<!\\.chr)\\.gtf\\.gz$", checksum, perl = TRUE)]
url2.5 <- sub(".*\\s", "", url2)
url3 <- paste0(url, url2.5)
h <- new_handle()
handle_setopt(h, timeout = 360)
curl_download(url3, paste0(gtfdest, "/", urlSpecific, ".gtf.gz"), handle = h)
gunzip(paste0(gtfdest, "/", urlSpecific, ".gtf.gz"), paste0(gtfdest, "/", urlSpecific, ".gtf"), remove = TRUE)
gtfFilePath <- paste0(gtfdest, "/", urlSpecific, ".gtf")
asmblyGeneCount <- dataFromGtf(gtfFilePath)
csv$asmblyGeneCount <- asmblyGeneCount
fwrite(csv, file = resultsCsv, row.names = FALSE)
}
}
}
execTime <- round(as.numeric(difftime(Sys.time(), startTime, units = "mins")), 2)
print(noquote(paste0("   ", execTime, " minutes")))
}
# load stuff in
source("constants.and.paths.R")
source("functions.R")
loadPackages(requiredPackages)
species <- "Sarcophilus harrisii"
# load stuff in
source("constants.and.paths.R")
source("functions.R")
# Load necessary package
library(dplyr)
# Specify the folder path
folder_path <- "C:/Users/zhaob/Desktop/gene_density/results/vertebrates/individualSpeciesResults"  # Replace with your folder path
# List all CSV files in the folder
csv_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)
# Function to read, modify, and save CSV files
process_csv <- function(file) {
# Read the CSV file
data <- read.csv(file)
# Remove the 6th, 7th, 8th, and 9th columns
modified_data <- data[, -c(6, 7, 8, 9)]
# Save the modified data to a new CSV file
write.csv(modified_data, file, row.names = FALSE)
}
# Apply the function to each CSV file
lapply(csv_files, process_csv)
# Print a message indicating completion
cat("Processing complete. All specified columns removed from CSV files.")
one <- read.csv("C:\Users\zhaob\Desktop\gene_density\data\vertebrates\clades_gnsz.csv")
one <- read.csv("C:/Users/zhaob/Desktop/gene_density/data/vertebrates/clades_gnsz.csv")
two <- read.csv("C:/Users/zhaob/Desktop/cladeData.csv")
one$species == two$species
library(ape)
install.packages("ape")
library(ape)
version
# load stuff in
library(phytools)
dat <- read.csv("../results/vertebrates/final_results.csv")
library(car)
library(FactoMineR)
install.packages("FactoMineR")
dat <- data("iris")
dat <- data("iris")
data("iris")
force(iris)
View(iris)
data("iris")
names(iris) <- dat
?prcomp
pca <- prcomp(iris[, c(1:4)])
View(pca)
View(pca)
View(pca)
hist(pca$sdev)
View(pca)
y <- pca$sdev^2/sum(pca$sdev)
y
View(iris)
y
pca$sdev
y <- pca$sdev^2/sum(pca$sdev^2)
barplot(y, names.arg = c("pc1", "pc2", "pc3", "pc4"))
View(iris)
dat <- iris
rm(iris)
View(dat)
View(dat)
names(dat) <- c("sepl", "sepw", "petl", "petw", "sp")
View(pca)
View(dat)
pca <- prcomp(dat[, c(1:4)])
y <- pca$sdev^2/sum(pca$sdev^2)
barplot(y, names.arg = c("pc1", "pc2", "pc3", "pc4"))
loadings <- pca$rotation
View(loadings)
View(loadings)
library(ggplot2)
ggplot(loadings, aes(x = PC1, y = PC2)) +
# vectors
geom_segment(aes(x = 0, y = 0, xend = PC1, yend = PC2),
# arrows
arrow = arrow(), color = "blue") +
# vector labels
geom_text_repel(data = loadings, aes(x = PC1, y = PC2, label = rownames(loadings)),
size = 4, nudge_x = 0.1, nudge_y = 0.1,
max.overlaps = Inf, force = 180) +
# axis labels
labs(# title = "PCA Biplot",
x = "Principal Component 1",
y = "Principal Component 2") +
theme(plot.title = element_text(hjust = 0.475),
plot.subtitle = element_text(hjust = 0.475),
axis.line = element_line(color = "black"),
panel.background = element_rect(fill = "white"),
panel.grid.major = element_line(color = "black", linetype = "dotted", size = 0.25),
legend.position = "none")
y
sum(y)
library(ggrepel)
ggplot(loadings, aes(x = PC1, y = PC2)) +
# vectors
geom_segment(aes(x = 0, y = 0, xend = PC1, yend = PC2),
# arrows
arrow = arrow(), color = "blue") +
# vector labels
geom_text_repel(data = loadings, aes(x = PC1, y = PC2, label = rownames(loadings)),
size = 4, nudge_x = 0.1, nudge_y = 0.1,
max.overlaps = Inf, force = 180) +
# axis labels
labs(# title = "PCA Biplot",
x = "Principal Component 1",
y = "Principal Component 2") +
theme(plot.title = element_text(hjust = 0.475),
plot.subtitle = element_text(hjust = 0.475),
axis.line = element_line(color = "black"),
panel.background = element_rect(fill = "white"),
panel.grid.major = element_line(color = "black", linetype = "dotted", size = 0.25),
legend.position = "none")
barplot(y, names.arg = c("pc1", "pc2", "pc3", "pc4"))
unique(dat$sepl)
unique(dat$sp)
View(pca)
pca$x
plot(dat$petl,
dat$sepl,
cool = rep(c("green", "blue", "purple"), each = 50),
pch = 16,
cex = 0.7)
plot(dat$petl,
dat$sepl,
col = rep(c("green", "blue", "purple"), each = 50),
pch = 16,
cex = 0.7)
plot(pca$x[, 1],
pca$x[, 2],
col = rep(c("green", "blue", "purple"), each = 50),
pch = 16,
cex = 0.7)
plot(dat$petl,
dat$sepl,
col = rep(c("green", "blue", "purple"), each = 50),
pch = 16,
cex = 0.7)
plot(pca$x[, 1],
pca$x[, 2],
col = rep(c("green", "blue", "purple"), each = 50),
pch = 16,
cex = 0.7)
View(pca)
pca$x
PC1 <- pca$x[, 1]
pc1 <- pca$x[, 1]
pc2 <- pca$x[, 2]
dat <- dat.frame(pc1, pc2)
dat <- data.frame(pc1, pc2)
library(car)
library(FactoMineR)
library(ggplot2)
library(ggrepel)
data("iris")
pca <- prcomp(iris[, c(1:4)])
y <- pca$sdev^2/sum(pca$sdev^2)
barplot(y, names.arg = c("pc1", "pc2", "pc3", "pc4"))
pc1 <- pca$x[, 1]
pc2 <- pca$x[, 2]
dat <- data.frame(pc1, pc2)
dat <- data.frame(pca$x[, c(1, 2)])
dat <- data.frame(pca$x[, c(1, 2)])
ggplot(dat, aes(x = PC1, y = PC2)) +
geom_point()
library(FactoMineR)
pca2 <- PCA(iris[, 1:4], graph = T)
loadings <- pca$rotation
ggplot(loadings, aes(x = PC1, y = PC2)) +
# vectors
geom_segment(aes(x = 0, y = 0, xend = PC1, yend = PC2),
# arrows
arrow = arrow(), color = "blue") +
# vector labels
geom_text_repel(data = loadings, aes(x = PC1, y = PC2, label = rownames(loadings)),
size = 4, nudge_x = 0.1, nudge_y = 0.1,
max.overlaps = Inf, force = 180) +
# axis labels
labs(# title = "PCA Biplot",
x = "Principal Component 1",
y = "Principal Component 2") +
theme(plot.title = element_text(hjust = 0.475),
plot.subtitle = element_text(hjust = 0.475),
axis.line = element_line(color = "black"),
panel.background = element_rect(fill = "white"),
panel.grid.major = element_line(color = "black", linetype = "dotted", size = 0.25),
legend.position = "none")
library(FactoMineR)
pca2 <- PCA(iris[, 1:4], graph = T)
loadings <- pca$rotation
ggplot(loadings, aes(x = PC1, y = PC2)) +
# vectors
geom_segment(aes(x = 0, y = 0, xend = PC1, yend = PC2),
# arrows
arrow = arrow(), color = "blue") +
# vector labels
geom_text_repel(data = loadings, aes(x = PC1, y = PC2, label = rownames(loadings)),
size = 4, nudge_x = 0.1, nudge_y = 0.1,
max.overlaps = Inf, force = 180) +
# axis labels
labs(# title = "PCA Biplot",
x = "Principal Component 1",
y = "Principal Component 2") +
theme(plot.title = element_text(hjust = 0.475),
plot.subtitle = element_text(hjust = 0.475),
axis.line = element_line(color = "black"),
panel.background = element_rect(fill = "white"),
panel.grid.major = element_line(color = "black", linetype = "dotted", size = 0.25),
legend.position = "none")
library(FactoMineR)
pca2 <- PCA(iris[, 1:4], graph = T)
df <- read.csv("../results/vertebrates/parsed.csv")
rm(list=ls())
q()
# transform results
dat <- read.csv("../results/vertebrates/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
# transform results
dat <- read.csv("../results/vertebrates/parsed.csv")
setwd("~/GitHub/genedensity/analysis")
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Parses results and calculates additional statistics
# to summarize contigs for each species
# contig sum/assembly size ratio threshold
thrs <- 0.8
dat <- read.csv("../data/data.csv")
# combine raw contig results
library(data.table)
dir <- "../results/individual_species_results"
files <- paste0(dir, "/",  list.files(dir))
contigs <- lapply(files, fread)
contigs <- as.data.frame(rbindlist((contigs), fill = TRUE))
# parse by contig size
contigs <- contigs[contigs$size.Mbp >= 10, ]
# remove species with less than 2 contigs
rm <- names(table(contigs$species)[table(contigs$species) < 2])
contigs <- contigs[!(contigs$species %in% rm), ]
# test new method
parsed <- data.frame()
for (z in unique(contigs$species)) {
sub <- contigs[contigs$species == z, ]
cont <- sum(sub$size.Mbp)
total <- contigs[contigs$species == z, ]$asmblysize[1]
if (cont/total >= thrs) {
parsed <- rbind(parsed, sub)
}
}
# calculate stats based on parsed results
sp <- unique(parsed$species)
final <- data.frame()
for (species in sp) {
i <- species
sub <- parsed[which(parsed$species == i), ]
if (nrow(sub) > 0){
fit <- summary(glm(sub$genecount ~ sub$size.Mbp))
beta <- fit$coefficients[2, 1]
pval.beta <- fit$coefficients[2, 4]
rsq <- summary(lm(sub$genecount ~ sub$size.Mbp))$r.squared
weightmean <- sum(sub$genedens * sub$size.Mbp) / sum(sub$size.Mbp)
weightsd <- sqrt(sum(sub$size.Mbp * (sub$genedens - weightmean)^2) / sum(sub$size.Mbp))
weightcv <- weightsd / weightmean
contig.stats <- data.frame(species, beta, pval.beta, rsq, weightmean, weightsd, weightcv)
} else {
beta <- pval.beta <- rsq <- weightmean <- weightsd <- weightcv <- NA
contig.stats <- data.frame(species, beta, pval.beta, rsq, weightmean, weightsd, weightcv)
}
final <- rbind(final, merge(merge(dat[dat$species == species, ], contig.stats, by = "species"), sub, by = "species", all = TRUE))
}
#assign clades
final$clade <- final$class
final[final$clade %in% "Aves", ]$clade <- "Sauria"
final[final$clade %in% "Reptilia", ]$clade <- "Sauria"
final[!(final$clade %in% c("Actinopterygii", "Mammalia", "Sauria")), ]$clade <- "Others"
final$cont.asmb.rat.cutoff <- thrs
# reorder columns
final <- final[, c(1, 23, 2:8, 12:17, 22, 24, 9:11, 18:21)]
# write csv
write.csv(final, "../results/parsed.csv", row.names = FALSE)
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Calculates statistics to summarize repeat landscape
# characteristics for each species. saves one file with parsed
# contigs and another file for parsed contigs
# calculate stats
files <- list.files("../results/divsums")
sp <- gsub("_", " ", gsub(".divsum$", "", files))
dat <- read.csv("../results/parsed.csv")
asmbsz <- dat[!duplicated(dat$species), ]
asmbsz <- asmbsz[asmbsz$species %in% sp, ]
asmbsz <- setNames(asmbsz$asmblysize.Mbp*1000000, asmbsz$species)
repstats <- data.frame()
for (i in 1:length(sp)) {
species <- sp[i]
# read text file into lines
lines <- readLines(paste0("../results/divsums/", files[i]))
# look for the start of relevant information
phrase <- "Coverage for each repeat class and divergence (Kimura)"
start.index <- match(phrase, lines) + 1
# condense relevant lines into a table
lines <- lines[start.index:length(lines)]
table <- read.table(textConnection(lines),
sep = " ",
header = TRUE)
# drop NA columns
table <- table[-c(which(sapply(table, function(col) all(is.na(col)))))]
# condense table
classes <- c("LINE", "SINE", "LTR", "DNA", "RC", "Div", "Unknown")
for (j in classes) {
pat <- paste0("^", j, "(\\.|$)")
headers <- grep(pat, names(table), value = TRUE)
sub <- table[, headers]
sums <- rowSums(as.matrix(sub))
table <- table[, !names(table) %in% headers]
assign(j, sums)
}
Others <- rowSums(as.matrix(table))
table <- data.frame(Div, LINE, SINE, LTR, DNA, RC, Others, Unknown)
# all repeat total and median
rep.bp <- rowSums(table[, !names(table) == "Div"])
total.rep.pct <- sum((rep.bp / asmbsz[i]) * 100)
total.rep.median <- which(cumsum(rep.bp) > sum(rep.bp)/2)[1]
for (k in classes) {
assign(paste0(tolower(k), ".rep.pct"), sum(table[k] / asmbsz[i] * 100))
assign(paste0(tolower(k), ".rep.median"), which(cumsum(table[k]) > sum(table[k])/2)[1])
}
# build dataframe
df <- data.frame(species,
total.rep.pct,
total.rep.median,
line.rep.pct,
line.rep.median,
sine.rep.pct,
sine.rep.median,
ltr.rep.pct,
ltr.rep.median,
dna.rep.pct,
dna.rep.median,
rc.rep.pct,
rc.rep.median
)
repstats <- rbind(repstats, df)
}
df <- merge(dat, repstats, by = "species", all.x = TRUE)
# reorganize and save results
df <- df[, c(1:20, 25:36, 21:24)]
write.csv(df,
"../results/parsed.csv",
row.names = FALSE)
qwert <- list()
classes <- c("total", "line", "sine", "ltr", "dna", "rc")
for (qwe in classes) {
dat <- read.csv("../results/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat[[paste0(qwe, ".rep.median")]]/70)
dat <- na.omit(dat[, c("species", "rsq", "clade", "median.trans")])
dat <- dat[dat$clade == "Mammalia", ]
dat <- dat[dat$species != "Callithrix jacchus", ]
library(phytools)
tree <- read.tree("../data/formatted_tree.nwk")
tree$tip.label <- gsub("_", " ", tree$tip.label)
int <- intersect(tree$tip.label, dat$species)
pruned.tree <- keep.tip(tree, int)
dat1 <- dat[dat$species %in% int, ]
dat1 <- dat1[match(pruned.tree$tip.label, dat1$species), ]
model <- glm(rsq ~ median.trans, data = dat1)
res <- setNames(resid(model), dat1$species)
signal <- phylosig(pruned.tree, res, method="lambda", test=TRUE)[4]
if (signal < 0.05) {
library(nlme)
qwert[[paste0(qwe, ".slope")]] <- summary(gls(rsq ~ median.trans, data = dat1))$tTable[2, 1]
qwert[[paste0(qwe, ".p")]] <- summary(gls(rsq ~ median.trans, data = dat1))$tTable[2, 4]
library(piecewiseSEM)
qwert[[paste0(qwe, ".r2")]] <- rsquared(gls(rsq ~ median.trans, data = dat1))[[5]]
} else {
qwert[[paste0(qwe, ".slope")]] <- summary(glm(rsq ~ median.trans, data = dat))$coefficients[2, 1]
qwert[[paste0(qwe, ".p")]] <- summary(glm(rsq ~ median.trans, data = dat))$coefficients[2, 4]
library(piecewiseSEM)
qwert[[paste0(qwe, ".r2")]] <- rsquared(glm(rsq ~ median.trans, data = dat))[[5]]
}
}
qwert <- as.data.frame(qwert)
View(qwert)
