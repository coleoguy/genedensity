library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
# subset data
dat <- na.omit(dat[, c("species", "rsq", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# product of total repeat and median
plot(dat$median.trans * dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
term <- dat$median.trans * dat$totalrep.prop
abline(glm(dat$rsq ~ term, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ term))
legend("bottomright",
legend = round(seq(min(dat$median.trans * dat$totalrep.prop), max(dat$median.trans * dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# product of total repeat and median
plot(dat$median.trans * dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
term <- dat$median.trans * dat$totalrep.prop
abline(glm(dat$rsq ~ term, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ term))
legend("bottomright",
legend = round(seq(min(dat$median.trans * dat$totalrep.prop), max(dat$median.trans * dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
View(dat)
View(dat)
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
View(dat)
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Parses results and calculates additional statistics
# to summarize contigs for each species
dat <- read.csv("../data/data.csv")
# combine raw contig results
library(data.table)
dir <- "../results/individual_species_results"
files <- paste0(dir, "/",  list.files(dir))
raw <- lapply(files, fread)
raw <- as.data.frame(rbindlist((raw), fill = TRUE))
# parse results
parsed <- raw[raw$size.Mbp >= 10, ]
sp.lessthanthree <- names(which(table(parsed$species) < 3))
parsed <- parsed[!(parsed$species %in% sp.lessthanthree), ]
# calculate stats based on parsed results and record the unparsed contigs
sp <- unique(parsed$species)
final <- data.frame()
for (species in sp) {
i <- species
sub <- parsed[which(parsed$species == i), ]
if (nrow(sub) > 0){
fit <- summary(glm(sub$genecount ~ sub$size.Mbp))
beta <- fit$coefficients[2, 1]
pval.beta <- fit$coefficients[2, 4]
rsq <- summary(lm(sub$genecount ~ sub$size.Mbp))$r.squared
sdgd <- sd(sub$genedens)
meangd <- mean(sub$genedens)
cor <- cor(sub$size.Mbp, sub$genecount)
weightmean <- sum(sub$genedens * sub$size.Mbp) / sum(sub$size.Mbp)
weightsd <- sqrt(sum(sub$size.Mbp * (sub$genedens - weightmean)^2) / sum(sub$size.Mbp))
weightcv <- weightsd / weightmean
chromsd <- sd(sub$size.Mbp)/mean(sub$size.Mbp)
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
} else {
beta <- meangd <- sdgd <- pval.beta <- rsq <- cor <- weightmean <- weightsd <- weightcv <- chromsd <- NA
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
}
final <- rbind(final, merge(merge(dat[dat$species == species, ], contig.stats, by = "species"), sub, by = "species", all = TRUE))
}
#assign clades
final$clade <- final$class
final[final$clade %in% "Aves", ]$clade <- "Sauria"
final[final$clade %in% "Reptilia", ]$clade <- "Sauria"
final[!(final$clade %in% c("Actinopterygii", "Mammalia", "Sauria")), ]$clade <- "Others"
# reorder columns
final <- final[, c(1, 27, 2:11, 26, 12:25)]
# write csv
write.csv(final, "../results/parsed.csv", row.names = FALSE)
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Calculates statistics to summarize repeat landscape
# characteristics for each species. saves one file with parsed
# contigs and another file for parsed contigs
# calculate stats
# library(e1071)
files <- list.files("../results/divsums")
sp <- gsub("_", " ", gsub(".divsum$", "", files))
dat <- read.csv("../results/parsed.csv")
asmbsz <- dat[!duplicated(dat$species), ]
asmbsz <- asmbsz[asmbsz$species %in% sp, ]
asmbsz <- asmbsz[order(asmbsz$species == sp), ]
asmbsz <- asmbsz$asmblysize.Mbp*1000000
repstats <- data.frame()
i <- 1
species <- sp[i]
# read text file into lines
lines <- readLines(paste0("../results/divsums/", files[i]))
# look for the start of relevant information
phrase <- "Coverage for each repeat class and divergence (Kimura)"
start.index <- match(phrase, lines) + 1
# condense relevant lines into a table
lines <- lines[start.index:length(lines)]
table <- read.table(textConnection(lines),
sep = " ",
header = TRUE)
# drop NA columns
table <- table[-c(which(sapply(table, function(col) all(is.na(col)))))]
# vector of divergence scores
div <- table$Div
# vector of the repeat content of each divergence score
rep.bp <- rowSums(table[, !names(table) == "Div"])
# repeat content in Mbp
totalrep.Mbp <- sum(rep.bp) / 1000000
totalrep.Mbp
# repeat content in percent coverage
rep.pct <- 0.0001 * (rep.bp / asmbsz[i]) # 0.0001% = (bp / Mbp) * (1 Mbp / 1000000 bp) * (100%)
totalrep.pct <- sum(rep.pct)
totalrep pictex()
totalrep.pct
# repeat content in percent coverage
rep.pct <- 0.01 * (rep.bp / asmbsz[i]) # 0.0001% = (bp / Mbp) * (1 Mbp / 1000000 bp) * (100%)
totalrep.pct <- sum(rep.pct)
totalrep.pct
# repeat content in percent coverage
rep.pct <- (rep.bp / asmbsz[i])
totalrep.pct <- sum(rep.pct)
totalrep.pct
# repeat content in percent coverage
rep.pct <- (rep.bp / asmbsz[i])
totalrep.pct <- sum(rep.pct) * 100
totalrep.pct
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Parses results and calculates additional statistics
# to summarize contigs for each species
dat <- read.csv("../data/data.csv")
# combine raw contig results
library(data.table)
dir <- "../results/individual_species_results"
files <- paste0(dir, "/",  list.files(dir))
raw <- lapply(files, fread)
raw <- as.data.frame(rbindlist((raw), fill = TRUE))
# parse results
parsed <- raw[raw$size.Mbp >= 10, ]
sp.lessthanthree <- names(which(table(parsed$species) < 3))
parsed <- parsed[!(parsed$species %in% sp.lessthanthree), ]
# calculate stats based on parsed results and record the unparsed contigs
sp <- unique(parsed$species)
final <- data.frame()
for (species in sp) {
i <- species
sub <- parsed[which(parsed$species == i), ]
if (nrow(sub) > 0){
fit <- summary(glm(sub$genecount ~ sub$size.Mbp))
beta <- fit$coefficients[2, 1]
pval.beta <- fit$coefficients[2, 4]
rsq <- summary(lm(sub$genecount ~ sub$size.Mbp))$r.squared
sdgd <- sd(sub$genedens)
meangd <- mean(sub$genedens)
cor <- cor(sub$size.Mbp, sub$genecount)
weightmean <- sum(sub$genedens * sub$size.Mbp) / sum(sub$size.Mbp)
weightsd <- sqrt(sum(sub$size.Mbp * (sub$genedens - weightmean)^2) / sum(sub$size.Mbp))
weightcv <- weightsd / weightmean
chromsd <- sd(sub$size.Mbp)/mean(sub$size.Mbp)
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
} else {
beta <- meangd <- sdgd <- pval.beta <- rsq <- cor <- weightmean <- weightsd <- weightcv <- chromsd <- NA
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
}
final <- rbind(final, merge(merge(dat[dat$species == species, ], contig.stats, by = "species"), sub, by = "species", all = TRUE))
}
#assign clades
final$clade <- final$class
final[final$clade %in% "Aves", ]$clade <- "Sauria"
final[final$clade %in% "Reptilia", ]$clade <- "Sauria"
final[!(final$clade %in% c("Actinopterygii", "Mammalia", "Sauria")), ]$clade <- "Others"
# reorder columns
final <- final[, c(1, 27, 2:11, 26, 12:25)]
# write csv
write.csv(final, "../results/parsed.csv", row.names = FALSE)
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Calculates statistics to summarize repeat landscape
# characteristics for each species. saves one file with parsed
# contigs and another file for parsed contigs
# calculate stats
# library(e1071)
files <- list.files("../results/divsums")
sp <- gsub("_", " ", gsub(".divsum$", "", files))
dat <- read.csv("../results/parsed.csv")
asmbsz <- dat[!duplicated(dat$species), ]
asmbsz <- asmbsz[asmbsz$species %in% sp, ]
asmbsz <- asmbsz[order(asmbsz$species == sp), ]
asmbsz <- asmbsz$asmblysize.Mbp*1000000
repstats <- data.frame()
for (i in 1:length(sp)) {
species <- sp[i]
# read text file into lines
lines <- readLines(paste0("../results/divsums/", files[i]))
# look for the start of relevant information
phrase <- "Coverage for each repeat class and divergence (Kimura)"
start.index <- match(phrase, lines) + 1
# condense relevant lines into a table
lines <- lines[start.index:length(lines)]
table <- read.table(textConnection(lines),
sep = " ",
header = TRUE)
# drop NA columns
table <- table[-c(which(sapply(table, function(col) all(is.na(col)))))]
# vector of divergence scores
div <- table$Div
# vector of the repeat content of each divergence score
rep.bp <- rowSums(table[, !names(table) == "Div"])
# repeat content in Mbp
totalrep.Mbp <- sum(rep.bp) / 1000000
# repeat content in percent coverage
rep.pct <- (rep.bp / asmbsz[i])
totalrep.pct <- sum(rep.pct) * 100
# divergence bin with median repeat
median <- which(cumsum(rep.pct) > sum(rep.pct)/2)[1]
# unused
# mean <- sum(divergence*rep.pct)/sum(rep.pct)
# k <- kurtosis(rep.pct)
# s <- skewness(rep.pct)
# max <- max(rep.pct)
# which <- which.max(rep.pct)
# s <- skewness(rep.pct)
# k <- kurtosis(rep.pct)
# build dataframe
df <- data.frame(species,
totalrep.Mbp,
totalrep.pct,
median
)
repstats <- rbind(repstats, df)
}
df <- merge(dat, repstats, by = "species", all.x = TRUE)
# reorganize and save results
df <- df[, c(1:23, 28:30, 24:27)]
write.csv(df,
"../results/parsed.csv",
row.names = FALSE)
# Model for mammals
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
# subset data
dat <- na.omit(dat[, c("species", "rsq", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
View(dat)
# Model for mammals
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
# subset data
dat <- na.omit(dat[, c("species", "rsq", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# product of total repeat and median
plot(dat$median.trans * dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
term <- dat$median.trans * dat$totalrep.prop
abline(glm(dat$rsq ~ term, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ term))
legend("bottomright",
legend = round(seq(min(dat$median.trans * dat$totalrep.prop), max(dat$median.trans * dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# average number of complete genomes
sum(dat$w)
# add an exponent to emphasize high quality genomes
dat$w <- dat$w^5
sum(dat$w)
hist(dat$w)
# model
model <- glm(rsq ~ chromnum.1n + median.trans + median.trans:chromnum.1n, weights = dat$w, data = dat)
summary(model)
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
# subset data
dat <- na.omit(dat[, c("species", "rsq", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# product of total repeat and median
plot(dat$median.trans * dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
term <- dat$median.trans * dat$totalrep.prop
abline(glm(dat$rsq ~ term, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ term))
legend("bottomright",
legend = round(seq(min(dat$median.trans * dat$totalrep.prop), max(dat$median.trans * dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# average number of complete genomes
sum(dat$w)
# add an exponent to emphasize high quality genomes
dat$w <- dat$w^5
sum(dat$w)
hist(dat$w)
# model
model <- glm(rsq ~ chromnum.1n + median.trans + median.trans:chromnum.1n, weights = dat$w, data = dat)
# convert to plotting format
x <- seq(min(dat$median.trans), max(dat$median.trans), length.out = 100)
y <- seq(min(dat$chromnum.1n), max(dat$chromnum.1n), length.out = 100)
grid <- expand.grid(median.trans = x, chromnum.1n = y)
grid$rsq <- predict(model, newdata = grid, type = "response")
z <- matrix(grid$rsq, nrow = length(x), ncol = length(y))
# plot
original <- par(no.readonly = TRUE)
# plot
par(mar = c(4, 4, 3, 8) + 0.1)
image(x = x,
y = y,
z = z,
col = viridis(100),
xlab = "",
ylab = "",
main = "Title")
mtext("Expansion Recency", side=1, line=2.5)
mtext("Chromosome Number", side=2, line=2.5)
contour(x,
y,
z,
add = TRUE,
col = "black",
lwd = 1,
drawlabels = FALSE)
par(new = TRUE)
par(mar = c(4, 25, 3, 6))
z_range <- seq(min(z), max(z), length.out = 100)
image(1,
z_range,
t(matrix(z_range)),
col = viridis(100),
xaxt = "n",
yaxt = "n",
xlab = "",
ylab = "")
axis(4, at = pretty(z_range), labels = round(pretty(z_range), 2))
mtext("Predicted Consistency", side=4, line=2.5)
par(mar = c(5.1, 4.1, 4.1, 2.1))
