# k <- kurtosis(rep.pct)
# build dataframe
df <- data.frame(species,
totalrep.Mbp,
totalrep.pct,
median
)
repstats <- rbind(repstats, df)
}
df <- merge(dat, repstats, by = "species", all.x = TRUE)
# reorganize and save results
df <- df[, c(1:23, 28:30, 24:27)]
write.csv(df,
"../results/parsed.csv",
row.names = FALSE)
# note: new parsing method kept 11 mammals and rsq~transformed median has slope -1.5715 and p value 0.02929; no need to exponentiate weights
# the 11 mammals consist of 4 Artiodactyla,
# 4 Carnivora,
# 1 Perissodactyla,
# and 2 Primates
# what about other clades?
# Model for mammals
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
d <- dat
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
contigs <- c()
for (h in dat$species) {
sub <- d[d$species == h, ]
contigs <- c(contigs, nrow(sub))
}
dat$contigs <- contigs
# subset data
dat <- na.omit(dat[, c("species", "rsq", "class", "order", "family", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp", "contigs")])
dat <- dat[dat$clade == "Mammalia", ]
# marsupials?
mars <- c()
for (g in 1:nrow(dat)) {
if (dat[g, ]$order %in% c("Didelphimorphia",
"Paucituberculata",
"Microbiotheria",
"Dasyuromorphia",
"Notoryctemorphia",
"Peramelemorphia",
"Diprotodontia")){
mars <- c(mars, TRUE)
} else {
mars <- c(mars, FALSE)
}
}
dat$mars <- mars
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
# marsupials
mars <- dat[, c("species", "mars", "rsq", "order")]
mars <- mars[mars$order != "Monotrema", ]
obs.diff <- mean(mars[mars$mars == TRUE, ]$rsq) - mean(mars[mars$mars == FALSE, ]$rsq)
null.diff <- c()
for (f in 1:10000) {
null <- sample(mars)
null.diff <- c(null.diff, mean(null[null$mars == TRUE, ]$rsq) - mean(null[null$mars == FALSE, ]$rsq))
}
p <- mean(abs(null.diff) >= abs(obs.diff))
print(paste0("p = ", p))
# nope
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# totsl repeat
plot(dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$totalrep.prop, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$totalrep.prop))
legend("bottomright",
legend = round(seq(min(dat$totalrep.prop), max(dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# product of total repeat and median
plot(dat$median.trans * dat$totalrep.prop,
dat$rsq,
col = cols,
pch = 16)
term <- dat$median.trans * dat$totalrep.prop
abline(glm(dat$rsq ~ term, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ term))
legend("bottomright",
legend = round(seq(min(dat$median.trans * dat$totalrep.prop), max(dat$median.trans * dat$totalrep.prop), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
# average number of complete genomes
sum(dat$w)
# add an exponent to emphasize high quality genomes
dat$w <- dat$w^5
sum(dat$w)
hist(dat$w)
# model
model <- glm(rsq ~ chromnum.1n + median.trans + median.trans:chromnum.1n, weights = dat$w, data = dat)
# generate model predictions and format results
x <- seq(min(dat$median.trans), max(dat$median.trans), length.out = 100)
y <- seq(min(dat$chromnum.1n), max(dat$chromnum.1n), length.out = 100)
grid <- expand.grid(median.trans = x, chromnum.1n = y)
grid$rsq <- predict(model, newdata = grid, type = "response")
z <- matrix(grid$rsq, nrow = length(x), ncol = length(y))
# plot
par(mar = c(4, 4, 3, 8))
image(x = x,
y = y,
z = z,
col = viridis(100),
xlab = "",
ylab = "",
main = "Title")
mtext("Expansion Recency", side=1, line=2.5)
mtext("Chromosome Number", side=2, line=2.5)
contour(x,
y,
z,
add = TRUE,
col = "black",
lwd = 1,
drawlabels = FALSE)
par(new = TRUE)
par(mar = c(4, 25, 3, 6))
z_range <- seq(min(z), max(z), length.out = 100)
image(1,
z_range,
t(matrix(z_range)),
col = viridis(100),
xaxt = "n",
yaxt = "n",
xlab = "",
ylab = "")
axis(4, at = pretty(z_range), labels = round(pretty(z_range), 2))
mtext("Predicted Consistency", side=4, line=2.5)
par(mar = c(5.1, 4.1, 4.1, 2.1))
# group species by very low chromosome numbers or very complete genomes
wgroup <- chromgroup <- c()
for (i in 1:nrow(dat)) {
if (dat[i, ]$w >= 0.95) {
wgroup <- c(wgroup, T)
} else {
wgroup <- c(wgroup, F)
}
if (dat[i, ]$chromnum.1n <= 10) {
chromgroup <- c(chromgroup, T)
} else {
chromgroup <- c(chromgroup, F)
}
}
# tests
dat$wgroup <- wgroup
dat$chromgroup <- chromgroup
wilcox.test(w ~ chromgroup, data = dat)
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
d <- dat
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
contigs <- c()
for (h in dat$species) {
sub <- d[d$species == h, ]
contigs <- c(contigs, nrow(sub))
}
dat$contigs <- contigs
# subset data
dat <- na.omit(dat[, c("species", "rsq", "class", "order", "family", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp", "contigs")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Parses results and calculates additional statistics
# to summarize contigs for each species
dat <- read.csv("../data/data.csv")
# combine raw contig results
library(data.table)
dir <- "../results/individual_species_results"
files <- paste0(dir, "/",  list.files(dir))
raw <- lapply(files, fread)
raw <- as.data.frame(rbindlist((raw), fill = TRUE))
# parse by contig size
raw <- raw[raw$size.Mbp >= 10, ]
# test new method
parsed <- data.frame()
for (z in unique(dat$species)) {
sub <- raw[raw$species == z, ]
total <- sum(sub$size.Mbp)
est <- dat[dat$species == z, ]$est.gnsz.Mbp
if (is.na(est) == TRUE) {
next
} else {
if (total/est >= 0.6) {
parsed <- rbind(parsed, sub)
}
}
}
# calculate stats based on parsed results
sp <- unique(parsed$species)
final <- data.frame()
for (species in sp) {
i <- species
sub <- parsed[which(parsed$species == i), ]
if (nrow(sub) > 0){
fit <- summary(glm(sub$genecount ~ sub$size.Mbp))
beta <- fit$coefficients[2, 1]
pval.beta <- fit$coefficients[2, 4]
rsq <- summary(lm(sub$genecount ~ sub$size.Mbp))$r.squared
sdgd <- sd(sub$genedens)
meangd <- mean(sub$genedens)
cor <- cor(sub$size.Mbp, sub$genecount)
weightmean <- sum(sub$genedens * sub$size.Mbp) / sum(sub$size.Mbp)
weightsd <- sqrt(sum(sub$size.Mbp * (sub$genedens - weightmean)^2) / sum(sub$size.Mbp))
weightcv <- weightsd / weightmean
chromsd <- sd(sub$size.Mbp)/mean(sub$size.Mbp)
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
} else {
beta <- meangd <- sdgd <- pval.beta <- rsq <- cor <- weightmean <- weightsd <- weightcv <- chromsd <- NA
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
}
final <- rbind(final, merge(merge(dat[dat$species == species, ], contig.stats, by = "species"), sub, by = "species", all = TRUE))
}
#assign clades
final$clade <- final$class
final[final$clade %in% "Aves", ]$clade <- "Sauria"
final[final$clade %in% "Reptilia", ]$clade <- "Sauria"
final[!(final$clade %in% c("Actinopterygii", "Mammalia", "Sauria")), ]$clade <- "Others"
# reorder columns
final <- final[, c(1, 27, 2:11, 26, 12:25)]
# write csv
write.csv(final, "../results/parsed.csv", row.names = FALSE)
unique(final$species)
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Calculates statistics to summarize repeat landscape
# characteristics for each species. saves one file with parsed
# contigs and another file for parsed contigs
# calculate stats
# library(e1071)
files <- list.files("../results/divsums")
sp <- gsub("_", " ", gsub(".divsum$", "", files))
dat <- read.csv("../results/parsed.csv")
asmbsz <- dat[!duplicated(dat$species), ]
asmbsz <- asmbsz[asmbsz$species %in% sp, ]
asmbsz <- asmbsz[order(asmbsz$species == sp), ]
asmbsz <- asmbsz$asmblysize.Mbp*1000000
repstats <- data.frame()
for (i in 1:length(sp)) {
species <- sp[i]
# read text file into lines
lines <- readLines(paste0("../results/divsums/", files[i]))
# look for the start of relevant information
phrase <- "Coverage for each repeat class and divergence (Kimura)"
start.index <- match(phrase, lines) + 1
# condense relevant lines into a table
lines <- lines[start.index:length(lines)]
table <- read.table(textConnection(lines),
sep = " ",
header = TRUE)
# drop NA columns
table <- table[-c(which(sapply(table, function(col) all(is.na(col)))))]
# vector of divergence scores
div <- table$Div
# vector of the repeat content of each divergence score
rep.bp <- rowSums(table[, !names(table) == "Div"])
# repeat content in Mbp
totalrep.Mbp <- sum(rep.bp) / 1000000
# repeat content in percent coverage
rep.pct <- (rep.bp / asmbsz[i]) * 100
totalrep.pct <- sum(rep.pct)
# divergence bin with median repeat
median <- which(cumsum(rep.pct) > sum(rep.pct)/2)[1]
# unused
# mean <- sum(divergence*rep.pct)/sum(rep.pct)
# k <- kurtosis(rep.pct)
# s <- skewness(rep.pct)
# max <- max(rep.pct)
# which <- which.max(rep.pct)
# s <- skewness(rep.pct)
# k <- kurtosis(rep.pct)
# build dataframe
df <- data.frame(species,
totalrep.Mbp,
totalrep.pct,
median
)
repstats <- rbind(repstats, df)
}
df <- merge(dat, repstats, by = "species", all.x = TRUE)
# reorganize and save results
df <- df[, c(1:23, 28:30, 24:27)]
write.csv(df,
"../results/parsed.csv",
row.names = FALSE)
# note: new parsing method kept 11 mammals and rsq~transformed median has slope -1.5715 and p value 0.02929; no need to exponentiate weights
# the 11 mammals consist of 4 Artiodactyla,
# 4 Carnivora,
# 1 Perissodactyla,
# and 2 Primates
# what about other clades?
# Model for mammals
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
d <- dat
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
contigs <- c()
for (h in dat$species) {
sub <- d[d$species == h, ]
contigs <- c(contigs, nrow(sub))
}
dat$contigs <- contigs
# subset data
dat <- na.omit(dat[, c("species", "rsq", "class", "order", "family", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp", "contigs")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
# median
cols <- viridis(length(unique(dat$w)), alpha = 0.45)[as.factor(dat$w)]
plot(dat$median.trans,
dat$rsq,
col = cols,
pch = 16)
abline(glm(dat$rsq ~ dat$median.trans, weights = dat$w), col = "blue")
abline(glm(dat$rsq ~ dat$median.trans))
legend("bottomright",
legend = round(seq(min(dat$median.trans), max(dat$median.trans), length.out = 5), 2),
fill = viridis(5),
title = "Legend")
summary(glm(rsq ~ median.trans, weights = w, data = dat))
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Parses results and calculates additional statistics
# to summarize contigs for each species
dat <- read.csv("../data/data.csv")
# combine raw contig results
library(data.table)
dir <- "../results/individual_species_results"
files <- paste0(dir, "/",  list.files(dir))
raw <- lapply(files, fread)
raw <- as.data.frame(rbindlist((raw), fill = TRUE))
# parse by contig size
raw <- raw[raw$size.Mbp >= 10, ]
# test new method
parsed <- data.frame()
for (z in unique(dat$species)) {
sub <- raw[raw$species == z, ]
total <- sum(sub$size.Mbp)
est <- dat[dat$species == z, ]$est.gnsz.Mbp
if (is.na(est) == TRUE) {
next
} else {
if (total/est >= 0.5) {
parsed <- rbind(parsed, sub)
}
}
}
# calculate stats based on parsed results
sp <- unique(parsed$species)
final <- data.frame()
for (species in sp) {
i <- species
sub <- parsed[which(parsed$species == i), ]
if (nrow(sub) > 0){
fit <- summary(glm(sub$genecount ~ sub$size.Mbp))
beta <- fit$coefficients[2, 1]
pval.beta <- fit$coefficients[2, 4]
rsq <- summary(lm(sub$genecount ~ sub$size.Mbp))$r.squared
sdgd <- sd(sub$genedens)
meangd <- mean(sub$genedens)
cor <- cor(sub$size.Mbp, sub$genecount)
weightmean <- sum(sub$genedens * sub$size.Mbp) / sum(sub$size.Mbp)
weightsd <- sqrt(sum(sub$size.Mbp * (sub$genedens - weightmean)^2) / sum(sub$size.Mbp))
weightcv <- weightsd / weightmean
chromsd <- sd(sub$size.Mbp)/mean(sub$size.Mbp)
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
} else {
beta <- meangd <- sdgd <- pval.beta <- rsq <- cor <- weightmean <- weightsd <- weightcv <- chromsd <- NA
contig.stats <- data.frame(species, beta, meangd, sdgd, pval.beta, rsq, cor, weightmean, weightsd, weightcv, chromsd)
}
final <- rbind(final, merge(merge(dat[dat$species == species, ], contig.stats, by = "species"), sub, by = "species", all = TRUE))
}
#assign clades
final$clade <- final$class
final[final$clade %in% "Aves", ]$clade <- "Sauria"
final[final$clade %in% "Reptilia", ]$clade <- "Sauria"
final[!(final$clade %in% c("Actinopterygii", "Mammalia", "Sauria")), ]$clade <- "Others"
# reorder columns
final <- final[, c(1, 27, 2:11, 26, 12:25)]
# write csv
write.csv(final, "../results/parsed.csv", row.names = FALSE)
# Zhaobo Hu
# zhaobohu2002@gmail.com
# Description: Calculates statistics to summarize repeat landscape
# characteristics for each species. saves one file with parsed
# contigs and another file for parsed contigs
# calculate stats
# library(e1071)
files <- list.files("../results/divsums")
sp <- gsub("_", " ", gsub(".divsum$", "", files))
dat <- read.csv("../results/parsed.csv")
asmbsz <- dat[!duplicated(dat$species), ]
asmbsz <- asmbsz[asmbsz$species %in% sp, ]
asmbsz <- asmbsz[order(asmbsz$species == sp), ]
asmbsz <- asmbsz$asmblysize.Mbp*1000000
repstats <- data.frame()
for (i in 1:length(sp)) {
species <- sp[i]
# read text file into lines
lines <- readLines(paste0("../results/divsums/", files[i]))
# look for the start of relevant information
phrase <- "Coverage for each repeat class and divergence (Kimura)"
start.index <- match(phrase, lines) + 1
# condense relevant lines into a table
lines <- lines[start.index:length(lines)]
table <- read.table(textConnection(lines),
sep = " ",
header = TRUE)
# drop NA columns
table <- table[-c(which(sapply(table, function(col) all(is.na(col)))))]
# vector of divergence scores
div <- table$Div
# vector of the repeat content of each divergence score
rep.bp <- rowSums(table[, !names(table) == "Div"])
# repeat content in Mbp
totalrep.Mbp <- sum(rep.bp) / 1000000
# repeat content in percent coverage
rep.pct <- (rep.bp / asmbsz[i]) * 100
totalrep.pct <- sum(rep.pct)
# divergence bin with median repeat
median <- which(cumsum(rep.pct) > sum(rep.pct)/2)[1]
# unused
# mean <- sum(divergence*rep.pct)/sum(rep.pct)
# k <- kurtosis(rep.pct)
# s <- skewness(rep.pct)
# max <- max(rep.pct)
# which <- which.max(rep.pct)
# s <- skewness(rep.pct)
# k <- kurtosis(rep.pct)
# build dataframe
df <- data.frame(species,
totalrep.Mbp,
totalrep.pct,
median
)
repstats <- rbind(repstats, df)
}
df <- merge(dat, repstats, by = "species", all.x = TRUE)
# reorganize and save results
df <- df[, c(1:23, 28:30, 24:27)]
write.csv(df,
"../results/parsed.csv",
row.names = FALSE)
# note: new parsing method kept 11 mammals and rsq~transformed median has slope -1.5715 and p value 0.02929; no need to exponentiate weights
# the 11 mammals consist of 4 Artiodactyla,
# 4 Carnivora,
# 1 Perissodactyla,
# and 2 Primates
# what about other clades?
# Model for mammals
library(viridis)
# transform results
dat <- read.csv("../results/parsed.csv")
d <- dat
dat <- dat[!duplicated(dat$species), ]
dat <- dat[!is.na(dat$chromnum.1n), ]
dat$median.trans <- 1 - (dat$median/70)
dat$totalrep.prop <- dat$totalrep.pct * 0.01
contigs <- c()
for (h in dat$species) {
sub <- d[d$species == h, ]
contigs <- c(contigs, nrow(sub))
}
dat$contigs <- contigs
# subset data
dat <- na.omit(dat[, c("species", "rsq", "class", "order", "family", "clade", "median.trans", "totalrep.prop", "chromnum.1n", "est.gnsz.Mbp", "asmblysize.Mbp", "contigs")])
dat <- dat[dat$clade == "Mammalia", ]
# remove assembly with bloated assembly size
dat <- dat[dat$species != "Callithrix jacchus", ]
# assign weights; weights approach 1 as assembly sizes approach genome sizes. weights tend toward 0 as assembly sizes deviate from genome sizes
dat$w <- 1 - (abs(dat$asmblysize.Mbp - dat$est.gnsz.Mbp) / dat$est.gnsz.Mbp)
summary(glm(rsq ~ median.trans, weights = w, data = dat))
View(fit)
View(dat)
View(dat)
df$order
table(dat$order)
View(dat)
